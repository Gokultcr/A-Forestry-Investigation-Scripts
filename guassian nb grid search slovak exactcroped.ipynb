{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c94669-af10-406e-9de4-45f5a3d49ae5",
   "metadata": {},
   "source": [
    "# Guassian Grid (test approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fffa35e-9014-46a7-afd3-5b15608691db",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a1251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import classification_report\n",
    "from skimage.feature import greycomatrix, greycoprops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ea9298-bf9e-4892-816e-aa28b85594e3",
   "metadata": {},
   "source": [
    "### Define dataset and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d1f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "dire=\"D:/Individual_Trees_photos/exatctcrop\"\n",
    "categories= ['European beech', 'European silver fir', 'Norway spruce', 'Sessile oak']\n",
    "\n",
    "data =[]\n",
    "SIZE = 200\n",
    "images =[]\n",
    "label1 =[]\n",
    "for category in categories:\n",
    "    path = os.path.join(dire, category)\n",
    "    label = categories.index(category)\n",
    "    \n",
    "    \n",
    "    for img in os.listdir(path):\n",
    "        imgpath = os.path.join(path,img)\n",
    "        tree_img = cv2.imread(imgpath,0)\n",
    "        try:\n",
    "            tree_img = cv2.resize(tree_img, (SIZE, SIZE)) #Resize images\n",
    "            #tree_img = cv2.resize(tree_img,(50,50))\n",
    "            image = np.array(tree_img).flatten()\n",
    "        \n",
    "            #data.append([image, label])\n",
    "            images.append(tree_img)\n",
    "            label1.append(label)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "images=np.array(images)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0653a154-d025-4d2c-a31b-679d333ea660",
   "metadata": {},
   "source": [
    "### GLCM feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c07388df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTOR function\n",
    "# input shape is (n, x, y, c) - number of images, x, y, and channels\n",
    "def feature_extractor(dataset):\n",
    "    image_dataset = pd.DataFrame()\n",
    "    for image in range(dataset.shape[0]):  #iterate through each file \n",
    "        #print(image)\n",
    "        \n",
    "        df = pd.DataFrame()  #Temporary data frame to capture information for each loop.\n",
    "        #Reset dataframe to blank after each loop.\n",
    "        \n",
    "        img = dataset[image, :,:]\n",
    "        \n",
    "        #Full image\n",
    "        #GLCM = greycomatrix(img, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "        GLCM = greycomatrix(img, [1], [0])       \n",
    "        GLCM_Energy = greycoprops(GLCM, 'energy')[0]\n",
    "        df['Energy'] = GLCM_Energy\n",
    "        GLCM_corr = greycoprops(GLCM, 'correlation')[0]\n",
    "        df['Corr'] = GLCM_corr       \n",
    "        GLCM_diss = greycoprops(GLCM, 'dissimilarity')[0]\n",
    "        df['Diss_sim'] = GLCM_diss       \n",
    "        GLCM_hom = greycoprops(GLCM, 'homogeneity')[0]\n",
    "        df['Homogen'] = GLCM_hom       \n",
    "        GLCM_contr = greycoprops(GLCM, 'contrast')[0]\n",
    "        df['Contrast'] = GLCM_contr\n",
    "        \n",
    "        GLCM2 = greycomatrix(img, [3], [0])       \n",
    "        GLCM_Energy2 = greycoprops(GLCM2, 'energy')[0]\n",
    "        df['Energy2'] = GLCM_Energy2\n",
    "        GLCM_corr2 = greycoprops(GLCM2, 'correlation')[0]\n",
    "        df['Corr2'] = GLCM_corr2       \n",
    "        GLCM_diss2 = greycoprops(GLCM2, 'dissimilarity')[0]\n",
    "        df['Diss_sim2'] = GLCM_diss2       \n",
    "        GLCM_hom2 = greycoprops(GLCM2, 'homogeneity')[0]\n",
    "        df['Homogen2'] = GLCM_hom2       \n",
    "        GLCM_contr2 = greycoprops(GLCM2, 'contrast')[0]\n",
    "        df['Contrast2'] = GLCM_contr2\n",
    "\n",
    "        GLCM3 = greycomatrix(img, [5], [0])       \n",
    "        GLCM_Energy3 = greycoprops(GLCM3, 'energy')[0]\n",
    "        df['Energy3'] = GLCM_Energy3\n",
    "        GLCM_corr3 = greycoprops(GLCM3, 'correlation')[0]\n",
    "        df['Corr3'] = GLCM_corr3       \n",
    "        GLCM_diss3 = greycoprops(GLCM3, 'dissimilarity')[0]\n",
    "        df['Diss_sim3'] = GLCM_diss3       \n",
    "        GLCM_hom3 = greycoprops(GLCM3, 'homogeneity')[0]\n",
    "        df['Homogen3'] = GLCM_hom3       \n",
    "        GLCM_contr3 = greycoprops(GLCM3, 'contrast')[0]\n",
    "        df['Contrast3'] = GLCM_contr3\n",
    "        \n",
    "        GLCM4 = greycomatrix(img, [0], [np.pi/4])       \n",
    "        GLCM_Energy4 = greycoprops(GLCM4, 'energy')[0]\n",
    "        df['Energy4'] = GLCM_Energy4\n",
    "        GLCM_corr4 = greycoprops(GLCM4, 'correlation')[0]\n",
    "        df['Corr4'] = GLCM_corr4       \n",
    "        GLCM_diss4 = greycoprops(GLCM4, 'dissimilarity')[0]\n",
    "        df['Diss_sim4'] = GLCM_diss4       \n",
    "        GLCM_hom4 = greycoprops(GLCM4, 'homogeneity')[0]\n",
    "        df['Homogen4'] = GLCM_hom4       \n",
    "        GLCM_contr4 = greycoprops(GLCM4, 'contrast')[0]\n",
    "        df['Contrast4'] = GLCM_contr4\n",
    "        \n",
    "        GLCM5 = greycomatrix(img, [0], [np.pi/2])       \n",
    "        GLCM_Energy5 = greycoprops(GLCM5, 'energy')[0]\n",
    "        df['Energy5'] = GLCM_Energy5\n",
    "        GLCM_corr5 = greycoprops(GLCM5, 'correlation')[0]\n",
    "        df['Corr5'] = GLCM_corr5       \n",
    "        GLCM_diss5 = greycoprops(GLCM5, 'dissimilarity')[0]\n",
    "        df['Diss_sim5'] = GLCM_diss5       \n",
    "        GLCM_hom5 = greycoprops(GLCM5, 'homogeneity')[0]\n",
    "        df['Homogen5'] = GLCM_hom5       \n",
    "        GLCM_contr5 = greycoprops(GLCM5, 'contrast')[0]\n",
    "        df['Contrast5'] = GLCM_contr5\n",
    "        \n",
    "        #Add more filters as needed\n",
    "        #entropy = shannon_entropy(img)\n",
    "        #df['Entropy'] = entropy\n",
    "\n",
    "        \n",
    "        #Append features from current image to the dataset\n",
    "        image_dataset = image_dataset.append(df)\n",
    "        \n",
    "    return image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afa3d8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract features from images\n",
    "image_features = feature_extractor(images)\n",
    "X_for_ML =image_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a125cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Energy      Corr   Diss_sim   Homogen     Contrast   Energy2     Corr2  \\\n",
      "0   0.043767  0.592606   6.340729  0.182096    94.230226  0.040301  0.315692   \n",
      "0   0.041195  0.716540   5.646910  0.208871    77.740528  0.038062  0.526766   \n",
      "0   0.048385  0.610120   5.431608  0.209645    68.679749  0.043551  0.296993   \n",
      "0   0.048134  0.616639   5.272236  0.223643    72.459070  0.043943  0.376390   \n",
      "0   0.027736  0.685927   9.877035  0.124185   210.608693  0.026197  0.530190   \n",
      "..       ...       ...        ...       ...          ...       ...       ...   \n",
      "0   0.016008  0.737339  25.037161  0.080473  1622.034799  0.012646  0.369207   \n",
      "0   0.014578  0.757840  14.277513  0.082505   378.746256  0.011893  0.248230   \n",
      "0   0.018239  0.714099  11.804020  0.101789   266.563719  0.014972  0.189475   \n",
      "0   0.014307  0.616226  19.128191  0.070751   729.361709  0.012527  0.264430   \n",
      "0   0.010769  0.619383  25.432613  0.048852  1216.443970  0.009727  0.313829   \n",
      "\n",
      "    Diss_sim2  Homogen2    Contrast2  ...   Energy4  Corr4  Diss_sim4  \\\n",
      "0    8.145482  0.145631   156.036650  ...  0.190262    1.0        0.0   \n",
      "0    7.210025  0.167765   126.144797  ...  0.174381    1.0        0.0   \n",
      "0    7.330635  0.160991   123.964137  ...  0.198515    1.0        0.0   \n",
      "0    6.821802  0.180797   116.865863  ...  0.195020    1.0        0.0   \n",
      "0   11.805685  0.103984   297.687614  ...  0.147930    1.0        0.0   \n",
      "..        ...       ...          ...  ...       ...    ...        ...   \n",
      "0   41.833832  0.041714  3849.354086  ...  0.100759    1.0        0.0   \n",
      "0   26.644086  0.038494  1174.160533  ...  0.102065    1.0        0.0   \n",
      "0   21.235330  0.050605   752.821168  ...  0.116860    1.0        0.0   \n",
      "0   27.969746  0.041625  1389.883604  ...  0.104365    1.0        0.0   \n",
      "0   35.839289  0.031261  2182.726650  ...  0.088671    1.0        0.0   \n",
      "\n",
      "    Homogen4  Contrast4   Energy5  Corr5  Diss_sim5  Homogen5  Contrast5  \n",
      "0        1.0        0.0  0.190262    1.0        0.0       1.0        0.0  \n",
      "0        1.0        0.0  0.174381    1.0        0.0       1.0        0.0  \n",
      "0        1.0        0.0  0.198515    1.0        0.0       1.0        0.0  \n",
      "0        1.0        0.0  0.195020    1.0        0.0       1.0        0.0  \n",
      "0        1.0        0.0  0.147930    1.0        0.0       1.0        0.0  \n",
      "..       ...        ...       ...    ...        ...       ...        ...  \n",
      "0        1.0        0.0  0.100759    1.0        0.0       1.0        0.0  \n",
      "0        1.0        0.0  0.102065    1.0        0.0       1.0        0.0  \n",
      "0        1.0        0.0  0.116860    1.0        0.0       1.0        0.0  \n",
      "0        1.0        0.0  0.104365    1.0        0.0       1.0        0.0  \n",
      "0        1.0        0.0  0.088671    1.0        0.0       1.0        0.0  \n",
      "\n",
      "[527 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_for_ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc3216-c10d-41b8-9bd8-f14df0e99c2f",
   "metadata": {},
   "source": [
    "### Training-testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa716e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X_for_ML, label1, test_size =0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4356adf8-8c3a-4880-906d-4ba22e48d398",
   "metadata": {},
   "source": [
    "### GNB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a3ad620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2 2 2 0 0 1 1 3 0 3 2 0 1 0 1 2 1 3 2 0 2 1 2 1 3 0 1 1 1 0 2 1 0 2 2\n",
      " 1 2 0 0 1 2 2 2 3 1 3 2 3 1 3 0 3 0 1 3 0 3 0 1 1 0 1 0 2 0 0 0 2 2 2 0 3\n",
      " 2 1 1 1 2 0 2 1 3 0 1 1 0 3 1 1 0 2 1 0 1 2 3 0 1 0 0 1 0 1 3 2 2 2 2 2 2\n",
      " 0 2 1 1 0 3 2 0 2 2 1 0 2 3 2 1 3 1 2 2 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model=GaussianNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "y_pred_nb = model.predict(xtest)\n",
    "print(y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15cf401d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score using Naive Bayes is: 62.12 %\n"
     ]
    }
   ],
   "source": [
    "score_nb = round(accuracy_score(y_pred_nb,ytest)*100,2)\n",
    "\n",
    "print(\"The accuracy score using Naive Bayes is: \"+str(score_nb)+\" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34aa541-79e9-4f87-a916-51c5e81f6e20",
   "metadata": {},
   "source": [
    "### Display parameters available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c825109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'priors': None, 'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "pprint(model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a349279d-b5c3-446f-be9e-f3da3b094f2c",
   "metadata": {},
   "source": [
    "### Grid search on available para."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e948c701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: [0.51898734 0.52658228 0.53670886 0.53417722 0.53417722 0.53924051\n",
      " 0.57974684 0.64050633 0.63544304 0.64556962 0.64556962 0.64556962\n",
      " 0.64556962 0.64556962], using {'var_smoothing': 1e-11}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_var_smoothing</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012601</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'var_smoothing': 0.01}</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.468354</td>\n",
       "      <td>0.531646</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009799</td>\n",
       "      <td>0.008612</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'var_smoothing': 0.001}</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.468354</td>\n",
       "      <td>0.531646</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>0.526582</td>\n",
       "      <td>0.033586</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004802</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'var_smoothing': 0.0001}</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.481013</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>0.536709</td>\n",
       "      <td>0.029524</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007403</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{'var_smoothing': 1e-05}</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.468354</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.534177</td>\n",
       "      <td>0.033395</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>{'var_smoothing': 1e-06}</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.534177</td>\n",
       "      <td>0.040348</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004998</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'var_smoothing': 1e-07}</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.468354</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>0.539241</td>\n",
       "      <td>0.036336</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'var_smoothing': 1e-08}</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.579747</td>\n",
       "      <td>0.032421</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'var_smoothing': 1e-09}</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.620253</td>\n",
       "      <td>0.640506</td>\n",
       "      <td>0.042059</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'var_smoothing': 1e-10}</td>\n",
       "      <td>0.670886</td>\n",
       "      <td>0.620253</td>\n",
       "      <td>0.670886</td>\n",
       "      <td>0.620253</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.635443</td>\n",
       "      <td>0.030380</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'var_smoothing': 1e-11}</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.620253</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.038394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'var_smoothing': 1e-12}</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.036687</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'var_smoothing': 1e-13}</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.036687</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'var_smoothing': 1e-14}</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.036687</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'var_smoothing': 1e-15}</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.036687</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.012601      0.010800         0.003399        0.000491   \n",
       "1        0.009799      0.008612         0.004001        0.000632   \n",
       "2        0.004802      0.000750         0.003197        0.000747   \n",
       "3        0.007403      0.004924         0.004800        0.003185   \n",
       "4        0.004801      0.000750         0.002999        0.000629   \n",
       "5        0.004998      0.000633         0.003398        0.000489   \n",
       "6        0.005599      0.000490         0.003421        0.000791   \n",
       "7        0.004400      0.000489         0.002400        0.000490   \n",
       "8        0.004601      0.000489         0.002802        0.000400   \n",
       "9        0.004400      0.000802         0.002600        0.000489   \n",
       "10       0.004400      0.000800         0.002601        0.000491   \n",
       "11       0.005201      0.000749         0.003200        0.000399   \n",
       "12       0.004000      0.000634         0.002800        0.000750   \n",
       "13       0.003600      0.000491         0.002399        0.001022   \n",
       "\n",
       "   param_var_smoothing                     params  split0_test_score  \\\n",
       "0                 0.01    {'var_smoothing': 0.01}           0.493671   \n",
       "1                0.001   {'var_smoothing': 0.001}           0.518987   \n",
       "2               0.0001  {'var_smoothing': 0.0001}           0.544304   \n",
       "3              0.00001   {'var_smoothing': 1e-05}           0.544304   \n",
       "4             0.000001   {'var_smoothing': 1e-06}           0.544304   \n",
       "5                  0.0   {'var_smoothing': 1e-07}           0.544304   \n",
       "6                  0.0   {'var_smoothing': 1e-08}           0.607595   \n",
       "7                  0.0   {'var_smoothing': 1e-09}           0.632911   \n",
       "8                  0.0   {'var_smoothing': 1e-10}           0.670886   \n",
       "9                  0.0   {'var_smoothing': 1e-11}           0.658228   \n",
       "10                 0.0   {'var_smoothing': 1e-12}           0.645570   \n",
       "11                 0.0   {'var_smoothing': 1e-13}           0.645570   \n",
       "12                 0.0   {'var_smoothing': 1e-14}           0.645570   \n",
       "13                 0.0   {'var_smoothing': 1e-15}           0.645570   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.468354           0.531646           0.544304   \n",
       "1            0.468354           0.531646           0.544304   \n",
       "2            0.481013           0.544304           0.544304   \n",
       "3            0.468354           0.556962           0.544304   \n",
       "4            0.455696           0.569620           0.544304   \n",
       "5            0.468354           0.556962           0.556962   \n",
       "6            0.518987           0.607595           0.582278   \n",
       "7            0.582278           0.658228           0.708861   \n",
       "8            0.620253           0.670886           0.620253   \n",
       "9            0.645570           0.708861           0.594937   \n",
       "10           0.645570           0.708861           0.594937   \n",
       "11           0.645570           0.708861           0.594937   \n",
       "12           0.645570           0.708861           0.594937   \n",
       "13           0.645570           0.708861           0.594937   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.556962         0.518987        0.033009               14  \n",
       "1            0.569620         0.526582        0.033586               13  \n",
       "2            0.569620         0.536709        0.029524               10  \n",
       "3            0.556962         0.534177        0.033395               11  \n",
       "4            0.556962         0.534177        0.040348               11  \n",
       "5            0.569620         0.539241        0.036336                9  \n",
       "6            0.582278         0.579747        0.032421                8  \n",
       "7            0.620253         0.640506        0.042059                6  \n",
       "8            0.594937         0.635443        0.030380                7  \n",
       "9            0.620253         0.645570        0.038394                1  \n",
       "10           0.632911         0.645570        0.036687                1  \n",
       "11           0.632911         0.645570        0.036687                1  \n",
       "12           0.632911         0.645570        0.036687                1  \n",
       "13           0.632911         0.645570        0.036687                1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameters\n",
    "\n",
    "\n",
    "var_smoothing = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]\n",
    "# priors=[0.25, 0.25, 0.5]\n",
    "\n",
    "param_grid1 = dict( var_smoothing = var_smoothing )\n",
    "\n",
    "# Build the gridsearch\n",
    "dfrst1 = GaussianNB(var_smoothing = var_smoothing)\n",
    "grid1 = GridSearchCV(estimator=dfrst1, param_grid=param_grid1, cv=5, n_jobs =-1)\n",
    "grid_results1 = grid1.fit(xtrain, ytrain)\n",
    "\n",
    "\n",
    "# Summarize the results in a readable format\n",
    "print(\"Best: {0}, using {1}\".format(grid_results1.cv_results_['mean_test_score'], grid_results1.best_params_))\n",
    "results_df1 = pd.DataFrame(grid_results1.cv_results_)\n",
    "results_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecc7e2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(var_smoothing=1e-11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = grid1.best_estimator_\n",
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2a99312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set : 0.663\n",
      "Accuracy on testing set : 0.652\n"
     ]
    }
   ],
   "source": [
    "gnb_new = GaussianNB(var_smoothing = 1e-11 )\n",
    "gnb_new.fit(xtrain, ytrain)\n",
    "\n",
    "print(\"Accuracy on training set : {:.3f}\".format(gnb_new.score(xtrain, ytrain)))\n",
    "print(\"Accuracy on testing set : {:.3f}\".format(gnb_new.score(xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e74735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
